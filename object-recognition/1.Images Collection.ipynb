{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4457315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#framework to get uniques identifiers for the images \n",
    "import uuid \n",
    "import os \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade35e36",
   "metadata": {},
   "source": [
    "## Création des dossiers de stockage des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2056bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"thumbsup\",\"thumbsdown\",\"thankyou\",\"livelong\"]\n",
    "numbers_img = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ba0281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/images'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow','workspace','images'  )\n",
    "IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7328b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posix'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a67f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation des images paths en fonction du Systeme d'exploitation\n",
    "if os.name == 'posix':\n",
    "    !mkdir -p {IMAGES_PATH}\n",
    "    #creation de sous dossier pour chaque label\n",
    "    for label in labels:\n",
    "        path = os.path.join(IMAGES_PATH,label)\n",
    "        if not os.path.exists(path):\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d886f",
   "metadata": {},
   "source": [
    "## capture des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2266cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lauch_picture = input(\"On commence,0:No 1:yes\")\n",
    "##if lauch_picture == 1:\n",
    "#for label in labels : \n",
    "#    cap = cv2.VideoCapture(0)\n",
    "#    print('collection images for {}'.format(label))\n",
    "#    time.sleep(5)\n",
    "#    for imgnum in range(numbers_img):\n",
    "#        print('collection images for {}'.format(imgnum))\n",
    "#        ret, frame = cap.read()\n",
    "#        imgname = os.path.join(IMAGES_PATH, label, label +'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "#        cv2.imwrite(imgname, frame)\n",
    "#        cv2.imshow('frame', frame)\n",
    "#        time.sleep(2)\n",
    "#        \n",
    "#        if cv2.waitKey(1)  & 0xFF ==ord('q'):\n",
    "#            break \n",
    "#            \n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows\n",
    "#    \n",
    "##elif lauch_picture== 0: \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0fd821-7f31-487e-9a93-a4308768253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/louismartindunord/Desktop/python/assistant-audio/env/lib/python3.10/site-packages (4.9.2)\n",
      "Requirement already satisfied: pyqt5 in /Users/louismartindunord/Desktop/python/assistant-audio/env/lib/python3.10/site-packages (5.15.7)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.11 in /Users/louismartindunord/Desktop/python/assistant-audio/env/lib/python3.10/site-packages (from pyqt5) (12.11.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.0 in /Users/louismartindunord/Desktop/python/assistant-audio/env/lib/python3.10/site-packages (from pyqt5) (5.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade lxml pyqt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7565f30-d801-45ad-98c5-9bed98f8ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELLING_PATH = os.path.join('tensorflow', 'labelling')\n",
    "if not os.path.exists(LABELLING_PATH):\n",
    "    ! mkdir {LABELLING_PATH}\n",
    "    !git clone https://github.com/heartexlabs/labelImg.git {LABELLING_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aaf4faf-f492-4b69-909d-096e026dc761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow/labelling'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELLING_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045c58b6-3f20-4b0c-ad49-3fd5a080dcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrcc5 -o libs/resources.py resources.qrc\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !cd {LABELLING_PATH} && make qt5py3\n",
    "if os.name == 'nt':\n",
    "    !cd {LABELLING_PATH}  && pyrcc5 -o lib/ressources.py resources.qrc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "691b3a47-4ca2-46d1-b0cc-a7cffb11cb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd {LABELLING_PATH} && python3 labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae48791-4737-4c26-9408-a381d770a6f0",
   "metadata": {},
   "source": [
    "## Création du trainning testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5970724b-cbfc-46b2-b83e-ef6168b28157",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a233194-71b4-453d-b8b0-32765e991727",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "288c4168-139a-4219-b5de-f3c4a4b3a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    " paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "095fe49a-f458-463a-90e6-79fa21492d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d17957-7831-4651-a374-7fed50eafac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082cf5e-3b34-4a6d-a4b9-4e7a0e467f79",
   "metadata": {},
   "source": [
    "## Download of the TF Pretrained Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c45b1af-bbf5-4b34-ac76-a51516dc4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced69287-0cab-4280-8509-a3528bf78d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f40ab95-fc7c-47f2-9c98-81420e500c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Install Tensorflow Object Detection \n",
    "#if os.name=='posix':  \n",
    "#    !  brew install protobuf-c\n",
    "#    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "#    \n",
    "#if os.name=='nt':\n",
    "#    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "#    wget.download(url)\n",
    "#    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "#    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "#    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "#    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "#    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3c52a-8a5f-403f-966b-f7e0a1e4abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python3 {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d58048b-7536-431c-a0e7-d2a1097d8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6f80ea6-75b7-40e8-aa74-400476da2776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix\n"
     ]
    }
   ],
   "source": [
    "print(os.name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82a51884-980c-4428-a8f9-0bfc3ebbdb15",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-16 16:08:23--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Résolution de download.tensorflow.org (download.tensorflow.org)… 2a00:1450:400c:c07::80, 142.250.178.144\n",
      "Connexion à download.tensorflow.org (download.tensorflow.org)|2a00:1450:400c:c07::80|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 20515344 (20M) [application/x-tar]\n",
      "Sauvegarde en : « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.5 »\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  28,4MB/s    ds 0,7s    \n",
      "\n",
      "2023-01-16 16:08:24 (28,4 MB/s) — « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.5 » sauvegardé [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "#téléchargement deplacement et dearchivage du model de supervisedlearning\n",
    "if os.name == \"posix\":\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f627f-1348-4825-9bf4-e0b8faeded4e",
   "metadata": {},
   "source": [
    "## Creation of the label map \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acd3f208-0552-4eeb-8567-be37641a73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{\"name\": \"ThumbsUp\", \"id\" :1}, {\"name\": \"ThumbDown\", \"id\" :2}, {\"name\": \"ThankYou\", \"id\" :3}, {\"name\": \"LiveLong\", \"id\" :4} ]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write('item { \\n')\n",
    "            f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "            f.write('\\tid:{}\\n'.format(label['id']))\n",
    "            f.write('}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80f75f81-70a9-402a-b0e9-b9f890e72e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \u001b[32mmain\u001b[m\n",
      "  speech_recognition\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5360b11-adb8-49a8-9c00-faf0730c1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avertissement : dépôt git embarqué ajouté : object-recognition/Tensorflow/labelling\n",
      "\u001b[33mastuce: You've added another git repository inside your current repository.\u001b[m\n",
      "\u001b[33mastuce: Clones of the outer repository will not contain the contents of\u001b[m\n",
      "\u001b[33mastuce: the embedded repository and will not know how to obtain it.\u001b[m\n",
      "\u001b[33mastuce: If you meant to add a submodule, use:\u001b[m\n",
      "\u001b[33mastuce: \u001b[m\n",
      "\u001b[33mastuce: \tgit submodule add <url> object-recognition/Tensorflow/labelling\u001b[m\n",
      "\u001b[33mastuce: \u001b[m\n",
      "\u001b[33mastuce: If you added this path by mistake, you can remove it from the\u001b[m\n",
      "\u001b[33mastuce: index with:\u001b[m\n",
      "\u001b[33mastuce: \u001b[m\n",
      "\u001b[33mastuce: \tgit rm --cached object-recognition/Tensorflow/labelling\u001b[m\n",
      "\u001b[33mastuce: \u001b[m\n",
      "\u001b[33mastuce: See \"git help submodule\" for more information.\u001b[m\n",
      "avertissement : dépôt git embarqué ajouté : object-recognition/Tensorflow/models\n",
      "[main af74bdf] avancer sur la partie object recognition\n",
      " 103 files changed, 2175 insertions(+)\n",
      " create mode 100644 object-recognition/.DS_Store\n",
      " create mode 100644 object-recognition/.ipynb_checkpoints/1.Images Collection-checkpoint.ipynb\n",
      " create mode 100644 object-recognition/1.Images Collection.ipynb\n",
      " create mode 100644 object-recognition/Tensorflow/.DS_Store\n",
      " create mode 160000 object-recognition/Tensorflow/labelling\n",
      " create mode 160000 object-recognition/Tensorflow/models\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/annotations/label_map.pbtxt\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.b7eaeed2-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.b7eaeed2-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.b9255b66-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.b9255b66-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.ba5c1f7e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.ba5c1f7e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.bb9718a8-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.bb9718a8-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.bcd244a4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/livelong/livelong.bcd244a4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.aec253f4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.aec253f4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.aff83b76-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.aff83b76-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b12fca68-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b12fca68-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b26a390e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b26a390e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b3a56366-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thankyou/thankyou.b3a56366-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a58c100e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a58c100e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a6cbda9e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a6cbda9e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a807157c-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a807157c-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a942438a-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.a942438a-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.aa7d99d4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.aa7d99d4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.9c4ac2ce-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.9d995230-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.9eda6cec-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.9eda6cec-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.a014bcde-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.a14b6378-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.a14b6378-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/livelong.bcd244a4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/livelong.bcd244a4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thankyou.b26a390e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thankyou.b26a390e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thumbsdown.aa7d99d4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thumbsdown.aa7d99d4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thumbsup.a014bcde-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/test/thumbsup.a14b6378-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.b7eaeed2-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.b7eaeed2-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.b9255b66-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.b9255b66-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.ba5c1f7e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.ba5c1f7e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.bb9718a8-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/livelong.bb9718a8-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.aec253f4-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.aec253f4-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.aff83b76-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.aff83b76-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.b12fca68-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.b12fca68-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.b3a56366-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thankyou.b3a56366-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a58c100e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a58c100e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a6cbda9e-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a6cbda9e-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a807157c-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a807157c-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a942438a-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsdown.a942438a-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsup.9c4ac2ce-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsup.9d995230-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsup.9eda6cec-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsup.9eda6cec-91b6-11ed-94d2-2af8bc751f3e.xml\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/images/train/thumbsup.a14b6378-91b6-11ed-94d2-2af8bc751f3e.jpg\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/.DS_Store\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      " create mode 100644 object-recognition/Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
      " create mode 100644 object-recognition/__init__.py\n",
      " create mode 100644 object-recognition/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.1\n",
      " create mode 100644 object-recognition/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.2\n",
      " create mode 100644 object-recognition/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.3\n",
      " create mode 100644 object-recognition/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.4\n",
      " create mode 100644 object-recognition/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.5\n",
      "Énumération des objets: 76, fait.\n",
      "Décompte des objets: 100% (76/76), fait.\n",
      "Compression par delta en utilisant jusqu'à 4 fils d'exécution\n",
      "Compression des objets: 100% (74/74), fait.\n",
      "Écriture des objets: 100% (75/75), 33.29 Mio | 10.04 Mio/s, fait.\n",
      "Total 75 (delta 26), réutilisés 0 (delta 0), réutilisés du pack 0\n",
      "remote: Resolving deltas: 100% (26/26), completed with 1 local object.\u001b[K\n",
      "To https://github.com/louismartindunord/assistant-audio.git\n",
      "   3c3ba70..af74bdf  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git add . \n",
    "!git commit -m'avancer sur la partie object recognition'\n",
    "! git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb8122-c56b-435e-888e-5ccde8b90ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
